---
title: "3rd Preliminary analysis for 2019-nCoV cases reported in some Asian countries and regions"
author: "Qingyuan Zhao"
date: "Febraury 15, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mice)
```

This preliminary analysis uses an updated version of the dataset in the [first preliminary analysis](https://htmlpreview.github.io/?https://github.com/qingyuanzhao/2019-nCov-Data/blob/master/Feb1.html) but attempts to use a simple model to acknowledge that this dataset contains only "shadows" of the real epidemic in Wuhan. Another important distinction is that we will directly model the infection time that can be imputed by the symptom onset time and the incubation interval reported in [Li et al. (2020)](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316).

# Data preprocessing

We first read and pre-process the data. This is very similar to the [first preliminary analysis](https://htmlpreview.github.io/?https://github.com/qingyuanzhao/2019-nCov-Data/blob/master/Feb1.html). The only difference is that we now start our date indexing from the December 1st instead of January 1st (because some infections happened in December).
```{r}
library(nCoV2019.data)
data(cases.outside.china)
data <- cases.outside.china

data$Confirmed <- date.process(data$Confirmed)
data$Arrived <- date.process(data$Arrived)
data$Symptom <- date.process(data$Symptom)
data$Initial <- date.process(data$Initial)
data$Hospital <- date.process(data$Hospital)
```

We focus on the following countries/regions: Japan, Singapore, Taiwan, HongKong, Macau, Korea, and only consider confirmed cases who were (most certainly) infected in Wuhan and travelled to these countries/regions:
```{r}
data$Country_or_Region <- do.call(rbind, strsplit(as.character(data$Case), "-"))[, 1]
data <- subset(data, Country_or_Region %in% c("Japan", "Singapore", "Taiwan", "Korea", "HongKong", "Macau"))
data <- subset(data, ! (Outside %in% c("Y", "L", "E")))

table(data$Country_or_Region)
```

Because of the lockdown of Wuhan on January 23rd, the infection time is no later than January 23rd, which is day
```{r}
(N <- 31 + 23)
```
in our series.

# Imputation of infection time

The first novelty of this analysis is that we will use existing information about the infection date of the 11-th confirmed case in Japan only stayed in Wuhan stayed during January 16--22 according to this [official report](https://www.mhlw.go.jp/stf/newpage_09239.html). We also know that the infection date ought to be no later than the arrival date. The *parse.infect* function creates two columns, /Infected_first/ and /Infected_last/, that contain such information
```{r}
data <- parse.infected(data)
data$Infected_last <- pmin(31+23, data$Infected_last) # Handle a few cases who arrived after Jan 23
subset(data, Case == "Japan-11")
```

The infection date is imputed by the symptom onset date minus a random draw from the distribution of the incubation period, truncated to the infection interval. This is implemented in the *impute.infected* function. Notice that [Li et al. (2020)](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316) only reported the estimated mean (5.2 days) and 95% quantile (12.5 days) of the incubation period. I matched them with a gamma distribution, although the histogram is slightly different from Figure 2A in that article.
```{r}
infected_imputed <- impute.infected(data$Symptom, data$Infected_first, data$Infected_last,
                                    incubation_mean = 5.2, incubation_sd = 3.7)
```

We can visualize the imputed infection time by counting the incidences on each day:
```{r}
as.count <- function(infected, last_date = 23+31) {
    table(factor(infected, levels = 1:last_date))
}
plot(as.count(infected_imputed))
```

# Distribution of the infection time

We can obtain a distribution of the infection time for these individuals by repeating the above procedure.

```{r, message = FALSE}
set.seed(20200215)
m <- 1000
```

```{r, cache = FALSE}
OI_imputed <- matrix(0, N, m)
for (i in 1:m) {
  infected_imputed <- impute.infected(data$Symptom, data$Infected_first, data$Infected_last,
                                      incubation_mean = 5.2, incubation_sd = 3.7)
  OI_imputed[, i] <- as.count(infected_imputed)
}
```

In the figure below, each black point represents a realization of the infection count. Their means are represented by the red curve, and the error bars are used show the standard error due to Monte-Carlo simulation.
```{r}
library(reshape2)
library(ggplot2)
df <- melt(OI_imputed[, 1:20])
names(df) <- c("date", "impute", "count")
df$date <- df$date - 1 + as.Date("2019-12-01")
df_summary <- data.frame(date = 1:N - 1 + as.Date("2019-12-01"),
                         count_mean = apply(OI_imputed, 1, mean),
                         count_sd = apply(OI_imputed, 1, sd) / sqrt(m - 1))
ggplot() + aes(x = date) +
  geom_point(data = df, aes(y = count), position = position_jitter(width = 0.5), alpha = 0.2) +
  geom_line(data = df_summary, aes(y = count_mean), alpha = 0.5, col = "red") +
  geom_errorbar(data = df_summary, aes(ymin = count_mean - count_sd, ymax = count_mean + count_sd), col = "red")
```

We see that the infection counts were initially growing exponentially but dropped in the last few days. This phenomenon may look surprising in the beginning, but actually this is due to we are using a sample that left Wuhan before the lockdown. For people infected on January 22, there was simply not enough time for all of them to leave Wuhan. Due to the nature of our sample, we posit the following model. Let $WI_t$ be the number of new infections in Wuhan on day $t$, among which $OI_t$ left Wuhan on or before January 23. We assume $WI_t$ was growing exponentially before January 23:
\begin{equation} \label{eq:wi}
  WI_t = WI_0 \cdot e^{rt}
\end{equation}
and $OI_t$ follows a Poisson distribution:
\begin{equation} \label{eq:oi}
  OI_t \sim \text{Poisson}(\sum_{s=t}^N OR_s * WI_t),
\end{equation}
where the $OR_s$ represents the proportion of people leaving Wuhan to the selected countries/regions. 

We will consider two choices of $(OR_s)_{s=1}^N$:
1. $OR_s = OR$ for $1 \le s \le N$, where the travelling rate is constant over time.
2. $OR_s = OR$ for $1 \le s \le N-3$ and $OR_s = 2 OR$ otherwise, where the travelling rate doubled in the last three days (this tries to capture the panic effect after human-to-human transmission was confirmed by Zhong Nanshan on the evening of January 20).

We will illustrate our analysis using the first choice. An immediate consequence of this model is that the logarithm of the expectation of $OI_t$ is given by
\begin{equation} \label{eq:log-linear}
  \log\big(\mathbb{E}[OI_t]\big) = rt + \log(N - t + 1) + \text{constant}.
\end{equation}
We can verify this model by estimating the left hand side using random samples of $(OI_t)_{t=1}^N$:
```{r}
df <- data.frame(date = 1:N, OI_mean = apply(OI_imputed, 1, mean))
fit <- lm(log(OI_mean / (N - date + 1)) ~ date, subset(df, date >= 1+31 & date <= 15+31))
plot(log(OI_mean / (N - date + 1)) ~ date, df)
abline(fit$coef[1], fit$coef[2], col = "red")
```

The slope of this simple straight line fit, which estimates $r$ according to the last display, is given by
```{r}
(r <- fit$coef[2])
```

This estimate means that the epidemic was doubling every
```{r}
log(2) / r
```
days. We can use the formula in [Wallinga and Lipsitch (2006)](https://royalsocietypublishing.org/doi/full/10.1098/rspb.2006.3754) to estimate the basic reproduction number from $r$, which is implemented in the *R0* package. This formula assumes the serial interval is normally distributed, and we will use the mean 7.5 and standard deviation 3.4 reported by [Li et al. (2020)](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316).
```{r}
r.to.R <- function(r, si_mean = 7.5, si_sd = 3.4) {
    GT <- R0::generation.time("gamma", c(si_mean, si_sd))
    sapply(r, function(r) as.numeric(R0:::R.from.r(r, GT)))
}
r.to.R(r)
```
This is much higher than the $R_0$ estimated by [Li et al. (2020)](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316).

# Uncertainty quantification

The above analysis does not recognize the fact that the distribution of $(OI_t)_{t=1}^N$ is drawn based on the observed cases, which is only a small (hopefully random) sample of the cases in Wuhan. We use Bayesian inference to quantify the sampling uncertainty. For each draw of $(OI_t)_{t=1}^n$, we fit the above model with the following prior:
\begin{align*}
  r &\sim \text{Exponential}(\text{mean} = \log(2)/7.4),\\
  WI_{32} &\sim \text{Gamma}(\text{mean} = 50, \text{sd} = 100), \\
  OP &\sim \text{Exponential}(OP_\text{prior}).
\end{align*}
The prior mean of $r$ is chosen as the estimate from [Li et al. (2020)](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316) who estimated the cases were doubly every $7.4$ days. We choose to put a diffuse Gamma prior on $WI_{32}$, the number of new infections on January 1st, which is more interpretable than $WI_1$.
```{r}
stan_data <- list(N = N,
                  r_prior_mean = log(2) / 7.4,
                  WI_Jan1_prior_mean = 50,
                  WI_Jan1_prior_sd = 100)
```
Finally we put an exponential prior on $OP$, the proportion of people leaving from Wuhan to the selected Asian countries/regions. We estimate the travel to the selected Asian countries/regions using air traffic planning data from December 30, 2019 to January 22, 2020, reported by this [web article](https://www.jiqizhixin.com/articles/2020-01-27-2). We assume twice as many people entered Hong Kong and Macau via train/car/ferry than air. We assume 80\% of the planned aircraft seats were taken.
```{r}
daily_travel <- (7078 * 3 + # Hong Kong
                 6154 * 3 + # Macau
                 3696 + 2698 + 1121 + # Taiwan
                 10680 + # Singapore
                 9080 + 6272 + 2656 + # Japan
                 6430) / 24 * 0.8  # Korea
daily_travel
stan_data$OR_prior_mean <- daily_travel / 11000000 ## divide by Wuhan's population
```

The next code chunk implements this Bayesian model in *stan*:
```{r, cache = FALSE, message = FALSE}
stan_code <- "
data {
  int<lower=0> N;
  int<lower=1> start;
  int<lower=start> end;
  int<lower=0> OI[N];
  real<lower=0> WI_Jan1_prior_mean;
  real<lower=0> WI_Jan1_prior_sd;
  real<lower=0> OR_prior_mean;
  real<lower=0> r_prior_mean;
  real<lower=0> offset[N];
}
parameters {
  real<lower=0> r;
  real<lower=0> WI_Jan1;
  real<lower=0> OR;
}
transformed parameters {
  vector[N] WI;
  vector[N] OI_mean;
  for (t in 1:N) {
    WI[t] = WI_Jan1 * exp(r * (t - 32));
    OI_mean[t] = offset[t] * OR * WI[t];
  }
}
model {
  r ~ exponential(1 / r_prior_mean);
  WI_Jan1 ~ gamma(WI_Jan1_prior_mean^2 / WI_Jan1_prior_sd^2,
                  WI_Jan1_prior_mean / WI_Jan1_prior_sd^2);
  OR ~ exponential(1 / OR_prior_mean);
  OI[start:end] ~ poisson(OI_mean[start:end]);
}
generated quantities {
  vector[N] WT;
  WT = cumulative_sum(WI);
}
"

library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
sm <- stan_model(model_code = stan_code)
```

The two choices of $(OR_s)_{s=1}^N$ are represented by the offset term in this code
```{r}
offset1 <- rev(cumsum(rev(rep(1, N))))
offset2 <- rev(cumsum(rev(c(rep(1, N-3), rep(2, 3)))))
```

For now we will illustrate the analysis using the first choice.
```{r}
stan_data$offset <- offset1
```

Our initial analysis of $\log(\mathbb{E}[OI_t])$ shows that the last few days seem to exhibit a different pattern. This perhaps correponds to increased prevention measure after Dr Zhong Nanshan confirmed human-to-human transmission on January 20, so we exclude the last three days from our analysis. Imputed infection times in the early period are also reliable because they are mostly determined by the tail distribution of incubation period. Thus we fit our model below using the period January 1 to January 20
```{r}
stan_data$start <- 1 + 31
stan_data$end <- 20 + 31
```

We draw 100 samples of $(OI)_{t=1}^N$ and obtain posterior samples of $r$, $WI_{32}$, and $AP$ in this model:
```{r, message = FALSE, cache = FALSE, warning = FALSE, message = "hide"}
file.remove("stanfit.out")
obtain.posterior <- function(symptom, stan_data, incubation_mean = 5.2, incubation_sd = 3.7) {
  
  capture.output(stan_data, file = "stanfit.out", append = TRUE)
  
  posterior <- list()
  for (impute in 1:m) {
    infected_imputed <- impute.infected(symptom,
                                        data$Infected_first, data$Infected_last,
                                        incubation_mean, incubation_sd)
    stan_data$OI <- as.count(infected_imputed, N)
    capture.output(fit <- sampling(sm, data  = stan_data, init = 3, iter = 5000, thin = 10),
                   file = "NUL") # supress the output of stan
    if (impute %% round(m/5) == 0) {
      capture.output(print(fit, pars = "r"), file = "stanfit.out", append = TRUE)
    }
    posterior[[impute]] <- extract(fit)
  }
  posterior

}

m <- 100

set.seed(20200215)
posterior <- obtain.posterior(data$Symptom, stan_data)
```

The posterior mean and 95% credible interval of $r$ is
```{r}
r_posterior <- unlist(lapply(posterior, function(posterior) posterior$r))
my.summary <- function(x) {c(mean = mean(x), CI.low = quantile(x, 0.025), CI.up = quantile(x, 0.975))}
my.summary(r_posterior)
my.summary(log(2) / r_posterior) ## doubling days
my.summary(r.to.R(r_posterior)) ## R0
```

# Sensitivity analysis

## Sensitivity to $OP_{\text{prior}}$

In the *stan* code we have also generated the total number of infections in Wuhan by the end of January 23.

```{r}
WT_Jan23_posterior <-
  unlist(lapply(posterior, function(posterior) posterior$WT[, N]))
my.summary(WT_Jan23_posterior)
```

However, this is not very reliable because it is closely correlated with the assumed rate of international traveling. People who traveled internationally are also more likely to be living in the city center and might have higher chances of infection.

Nevertheless, the growth exponent $r$ should be relatively insensitive to the choice. This is illustrated below where we assume the the prior mean of $OP$ is five times as before.

```{r, message = FALSE, cache = FALSE, warning = FALSE, message = "hide"}
stan_data$OP_prior_mean <- stan_data$OP_prior_mean * 5

set.seed(20200215)
posterior2 <- obtain.posterior(data$Symptom, stan_data)
```

```{r}
r_posterior2 <- unlist(lapply(posterior2, function(posterior) posterior$r))
my.summary(r_posterior2)
WT_Jan23_posterior2 <-
  unlist(lapply(posterior2, function(posterior) posterior$WT[, N]))
my.summary(WT_Jan23_posterior2)
```

## Sensitivity to incubation period, offset model, and study sample

Finally, we assess the sensitivity of our results to the distribution of the incubation interval, which is crucial in imputing the infection time. We also assess the sensitivity of our results to the study period (we only used simulated infections from January 1 to January 20) above.

```{r, message = FALSE, warning = FALSE, message = "hide"}
stan_data$OR_prior_mean <- daily_travel / 11000000 ## change the prior for OR back

settings <- expand.grid(offset = c(1,2), end = c(20+31, 23+31), incubation = c("2019-nCoV", "2019-nCoV-2"))
posterior <- list()
for (i in 1:nrow(settings)) {
  stan_data$offset <-  get(paste0("offset", settings$offset[i]))
  stan_data$end <- settings$end[i]
  set.seed(20200215)
  if (settings$incubation[i] == "2019-nCoV") {
    posterior[[i]] <- obtain.posterior(data$Symptom, stan_data,
                                       incubation_mean = 5.2, incubation_sd = 3.7)
  } else {
    posterior[[i]] <- obtain.posterior(data$Symptom, stan_data,
                                       incubation_mean = 6.5, incubation_sd = 2.6)
  }
}
```

```{r, message = FALSE}
posterior.to.output <- function(posterior) {
  posterior.myfun <- function(posterior) { # uses my.summary
    summ <- my.summary(posterior)
    summ <- signif(summ, 2)
    paste0(" ", summ[1], " [", summ[2], ", ", summ[3], "] ")
  }
  r_posterior <- unlist(lapply(posterior, function(posterior) posterior$r))
  r_output <- posterior.myfun(r_posterior)
  dd_output <- posterior.myfun(log(2) / r_posterior)
  R0_output <- posterior.myfun(r.to.R(r_posterior))
  c(r = r_output, dd = dd_output, R0 = R0_output)
}

output <- data.frame(do.call(rbind, lapply(posterior, posterior.to.output)))
output <- cbind(settings, output)

library(tables)
output$offset <- factor(output$offset)
output$end <- factor(as.numeric(output$end) + as.Date("2019-12-01") - 1)
output$incubation <- factor(output$incubation)
output$r <- as.character(output$r)
output$dd <- as.character(output$dd)
output$R0 <- as.character(output$R0)
tabular(incubation * offset ~ end * Heading() * identity * (r + dd + R0), output)
```
